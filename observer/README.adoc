= SDI Observer
Michal Minář
:toc:

The template spawns the `sdi-observer` pod that observes the
particular namespace where SAP Data Intelligence (SDI) runs and modifies
its deployments and configuration to enable its pods to run on Red Hat
OpenShift Container Platform (OCP).

== Functionality

The Observer performs the following actions.

=== Enables NFS exports in a container on RHCOS

On Red Hat Enterprise Linux CoreOS, SDI’s vsystem-vrep statefulset needs to be patched to mount
`emptyDir` volume at `/exports` directory in order to enable NFS exports in the container running
on top of overlayfs which is the default filesystem in RHCOS.

The observer pod modifies vsystem-vrep statefulset as soon as it appears to enable the NFS
exports.

=== Configures host path mount for diagnostic pods

SDI’s diagnostics-fluentd daemonset is patched to allow its pods to access log files on the host
system. It also modifies it to parse plain text log files instead of preconfigured JSON.

=== Exposes SDI System Management service

By default, observer also exposes SDI System Management service as a route using OpenShift
Ingress controller. The service is in OCP represented as `service/vsystem` resource.

*Influential parameters*:

[width="100%",cols="25%,15%,60%",options="header",]
|===
|Parameter |Default Value |Description
|`MANAGE_VSYSTEM_ROUTE` |`true` |Whether to create vsystem route for vsystem service in
`SDI_NAMESPACE`. The route will be of reencrypt type. The destination CA certificate for
communication with the vsystem service will be kept up to date by the observer. If set to
`remove`, the route will be deleted, which is useful to temporarily disable access to the vsystem
service during SDI updates.

|`VSYSTEM_ROUTE_HOSTNAME` | |Expose the vsystem service at the provided hostname using a route.
The value is applied only if `MANAGE_VSYSTEM_ROUTE` is enabled. The hostname defaults to
`vsystem-<SDI_NAMESPACE>.apps.<clustername>.<basedomainname>`
|===

=== Exposes SLC Bridge service

By default, observer also exposes SLC Bridge service as a route using OpenShift Ingress
controller. The service is in OCP represented as `service/slcbridgebase-service` resource in the
`SLCB_NAMESPACE`.

*Influential parameters*:

[width="100%",cols="25%,15%,60%",options="header",]
|===
|Parameter |Default Value |Description
|`MANAGE_SLCB_ROUTE` |`true` |Whether to create a route for SLC Bridge service in
`SLCB_NAMESPACE`. The route will be of passthrough type. If set to `remove`, the route will be
deleted.

|`SLCB_ROUTE_HOSTNAME` | |Expose the vsystem service at the provided hostname using a route. The
value is applied only if `MANAGE_SLCB_ROUTE` is enabled. The hostname defaults to
`<SLCB_NAMESPACE>.apps.<clustername>.<basedomainname>`
|===

=== _(optional)_ Ensures registry CA bundle gets imported

SDI requires its images to be hosted in a local container image registry secured by TLS. Often,
its certificates are self-signed. In order for SDI to to push and pull images to and from such a
registry, its certificate authority must be imported to SDI.

At the moment, SDI Observer allows to import the CA only to the initial DI Tenant during the
installation. This is also easily done manually by following
https://help.sap.com/viewer/a8d90a56d61a49718ebcb5f65014bbe7/3.1.latest/en-US/39e8e391d5984e919725e601f089db74.html[Setting
Up Certificates].

*Influential parameters*:

[width="100%",cols="25%,15%,60%",options="header",]
|===
|Parameter |Default Value |Description
|`INJECT_CABUNDLE` |`false` |Inject CA certificate bundle into SAP Data Intelligence pods. The
bundle can be specified with `CABUNDLE_SECRET_NAME`. It is needed if registry is secured by a
self-signed certificate.

|`CABUNDLE_SECRET_NAME` |`openshift-ingress-operator/router-ca` |The name of the secret containing
certificate authority bundle that shall be injected into Data Intelligence pods. By default, the
secret bundle is obtained from openshift-ingress-operator namespace where the router-ca secret
contains the certificate authority used to signed all the edge and reencrypt routes that are among
other things used for `SDI_REGISTRY` and NooBaa S3 API services. The secret name may be optionally
prefixed with `$namespace/`.
|===

For example, in the default value `openshift-ingress-operator/router-ca`, the
`openshift-ingress-operator` stands for secret’s namespace and `router-ca` stands for secret’s
name. If no `$namespace` prefix is given, the secret is expected to reside in `NAMESPACE` where
the SDI observer runs. All the entries present in the `.data` field having `.crt` or `.pem` suffix
will be concatenated to form the resulting `cert` file. This bundle will also be used to create
`cmcertificates` secret in `SDI_NAMESPACE` according to
https://help.sap.com/viewer/a8d90a56d61a49718ebcb5f65014bbe7/3.1.latest/en-US/39e8e391d5984e919725e601f089db74.html[Setting
Up Certificates].

=== _(optional)_ Enforces SDI resources to run on dedicated compute nodes

In order to maintain stability and performance of other workloads running on the same OCP cluster
as well as to improve security, one can dedicate a set of nodes to the SDI platform and ensure
that its pods are not run anywhere else.

The dedicated nodes must have a unique combination of labels not applicable to the other nodes.
These labels must be then specified in the `SDI_NODE_SELECTOR`. Usually, it is
`node-role.kubernetes.io/sdi=`. Observer then patches the `SDI_NAMESPACE` resource to make OCP
schedule pods running in this namespace only on the nodes matched by the node selector.

*Influential parameters*:

[width="100%",cols="25%,15%,60%",options="header",]
|===
|Parameter |Default Value |Description
|`SDI_NODE_SELECTOR` | |Make pods in `SDI_NAMESPACE` schedule only on nodes matching the given
node selector. The selector will be applied to the whole namespace and its daemonsets. Selector
can contain multiple `key=value` labels separated with commas.
Example value: `node-role.kubernetes.io/sdi=`
|===

=== _(optional)_ Deploys container image registry for SDI

Due to a couple of restrictions, it is not possible to mirror SDI images to the integrated OCP
image registry. Observer can be instructed to deploy another container image registry suitable to
host the images.

By default, the registry will be secured with TLS and will require authentication. It will be also
exposed via route utilizing the OpenShift Ingress controller. Unless overridden, credentials for
one user will be generated.

Note that by default, the route used to access the registry is secured by the Ingress controller’s
self-signed certificate. This certificate is not trusted by OpenShift platform for image pulls. To
make it trusted, please follow
https://access.redhat.com/articles/5100521#ocp-configure-ca-trust[8.2. Configure OpenShift to
trust container image registry].

*Influential parameters*:

[width="100%",cols="25%,15%,60%",options="header",]
|===
| Parameter                           | Default Value   | Description
| `DEPLOY_SDI_REGISTRY`               | `false`         | Whether to deploy container image
registry for the purpose of SAP Data Intelligence. Requires project admin role attached to the
`sdi-observer` service account. If enabled, `REDHAT_REGISTRY_SECRET_NAME` must be provided.

| `SDI_REGISTRY_STORAGE_CLASS_NAME`   |                 | Unless given, the default storage class
will be used.

| `REPLACE_PERSISTENT_VOLUME_CLAIMS`  | `false`         | Whether to replace existing persistent
volume claims like the one belonging to SDI Registry.

| `SDI_REGISTRY_AUTHENTICATION`       | `basic`         | Choose the authentication method of the
SDI Registry. Value `none` disables authentication altogether. If set to `basic`, the provided
htpasswd file is used to gate the incoming authentication requests.

| `SDI_REGISTRY_USERNAME`             |                 | Will be used to generate htpasswd file
to provide authentication data to the SDI Registry service as long as
`SDI_REGISTRY_HTPASSWD_SECRET_NAME` does not exist or `REPLACE_SECRETS` is `true`.

| `SDI_REGISTRY_PASSWORD`             |                 | Will be used to generate htpasswd file
to provide authentication data to the SDI Registry service as long as
`SDI_REGISTRY_HTPASSWD_SECRET_NAME` does not exist or `REPLACE_SECRETS` is `true`.

| `SDI_REGISTRY_HTPASSWD_SECRET_NAME` |                 | A secret with htpasswd file with
authentication data for the SDI image container. If given and the secret exists, it will be used
instead of `SDI_REGISTRY_USERNAME` and `SDI_REGISTRY_PASSWORD`.

| `SDI_REGISTRY_ROUTE_HOSTNAME`       |                 | Desired hostname of the exposed registry
service. Defaults to `container-image-registry-<NAMESPACE>-apps.<cluster_name>.<base_domain>`
Overrides and obsoletes the `REGISTRY` parameter.

| `SDI_REGISTRY_VOLUME_CAPACITY`      | `120Gi`         | Volume space available for container
images.

| `SDI_REGISTRY_VOLUME_ACCESS_MODE`   | `ReadWriteOnce` | If the given
`SDI_REGISTRY_STORAGE_CLASS_NAME` or the default storate class supports `ReadWriteMany` (`RWX`)
access mode, please change this to `ReadWriteMany`.
|===

For more information, please see link:../registry/[registry] directory.

=== _(deprecated)_ Enable iptables manipulation for pods

*NOTE*: this functionality is disabled by default as there are far better alternatives.

On Red Hat Enterprise Linux CoreOS, `vsystem-iptables` containers need to be run as privileged in
order to load iptables-related kernel modules. SDI containers named `vsystem-iptables` deployed as
part of every `vsystem-app` deployment attempt to modify iptables rules without having the
necessary permissions.

The ideal solution is to pre-load these modules during node’s startup. When not feasible, this
template can also fix the permissions on-the-fly as the deployments are created. The drawback is a
slower startup of SDI components.

To enable this functionality upon OCP Template’s instantiation, one must set
`MAKE_VSYSTEM_IPTABLES_PODS_PRIVILEGED` to `true`. Or set this as the environment variable on the
observer’s deployment config.

The recommended alternative is to
https://access.redhat.com/articles/5100521#preload-kernel-modules-post[pre-load the needed kernel
modules] on the compute nodes.

If not feasible (for example on IBM Cloud platform), one can achieve the same with the
link:../node-configurator/[Node Configurator daemonset].

_Influential parameters_:

[width="100%",cols="25%,15%,60%",options="header",]
|===
|Parameter | Default value | Description
|`MAKE_VSYSTEM_IPTABLES_PODS_PRIVILEGED` | `false` |Patch deployments with `vsystem-iptables`
container to make them privileged in order to load kernel modules they need. Unless `true`, it is
assumed that the modules have been pre-loaded on the worker nodes. This will make also
`vsystem-vrep-*` pod privileged.
|===

== Usage

The template must be instantiated before the SDI installation. It is strongly recommended to run
the observer in a separate namespace from SDI.

=== Prerequisites

. OCP cluster must be healthy including all the cluster operators.
. The
  link:https://docs.openshift.com/container-platform/4.6/registry/configuring-registry-operator.html[OCP
  integrated image registry] must be properly configured and working.
. _(`ubi-build` flavour)_ Pull secret for the registry.redhat.io must be configured. 

=== Template flavours

There are three different OCP templates designed for different scenarios:

[[template-flavours]]
[width="100%",cols="17%,35%,48%",options="header",]
|===
|Flavour | Template file| Description
|`ubi-build` | link:./ocp-template.json[] | (_recommended_, _connected_, _default_) To be used in
connected OCP clusters. A local build of SDI Observer image will be performed using UBI8 as the
base image.

|`ubi-prebuilt` | link:./ocp-prebuilt-image-template.json[] | (_disconnected_) To be used in
disconnected/offline/air-gapped OCP clusters. The image must be first mirrored to a local
registry.

|`custom-build` | link:./ocp-custom-source-image-template.json[] | For non-production, it is
possible to use a custom base image (e.g. CentOS). A very limited or no support will be offered in
case of issues though.
|===

The `FLAVOUR` parameter shall be set in the `run-observer-template.sh` script described
xref:#tmpl-run[below].

=== Ensuring Red Hat registry pull secret

In order to use `ubi-build` flavour, the pull secret must be configured:

. Get a secret for accessing registry.redhat.io at
  link:https://access.redhat.com/terms-based-registry/[Red Hat Registry Service Accounts]. See
  link:https://access.redhat.com/RegistryAuthentication[Red Hat Container Registry Authentication]
  for more information.
. Create a project to host SDI Observer (e.g. `sdi-observer`):
+
....
# oc new-project sdi-observer
....
+
. Create the downloaded secret in there and add it as a pull secret for builds:
+
....
 # oc create -f rht-registry-miminar-secret.yaml
 secret/1234567-miminar-pull-secret created
 # oc secrets link default 1234567-miminar-pull-secret --for=pull
....


[[tmpl-run]]
=== Template instantiation

Assuming the SDI will be run in the `SDI_NAMESPACE` which is different from the observer
`NAMESPACE`, instantiate the template with default parameters like this:

1. Download the run script from git repository like this:
+
....
# curl -O https://raw.githubusercontent.com/redhat-sap/sap-data-intelligence/master/observer/run-observer-template.sh
....
+
2. Edit the downloaded `run-observer-template.sh` file in your favorite editor. Especially, mind
   the `FLAVOUR`, `NAMESPACE`, `SDI_NAMESPACE` parameters.
+
3. Run it in bash like this:
+
....
# bash ./run-observer-template.sh
....
+
4. Keep the modified script around for case of updates.

==== General template parameters

[width="100%",cols="25%,15%,60%",options="header",]
|===
| Parameter           | Default value   | Description
| `SDI_NAMESPACE`     | `sdi`           | Kubernetes namespace where SAP Data Intelligence runs or
will be running.

| `NAMESPACE`         | `sdi-observer`  | Kubernetes namespace where SDI Observer runs or will be
running.

| `SLCB_NAMESPACE`    | `sap-slcbridge` | Kubernetes namespace where Software Lifecycle Container
Bridge runs or will be running.

| `DRY_RUN`           | `false`         | Make SDI Observer perform no changes to k8s resources.
The observer will only output what would have been done. Use the following command to monitor its
progress: `oc logs -n $NAMESPACE -f dc/sdi-observer` 

| `OCP_MINOR_RELEASE` | `4.6`           | Determines the desired release of oc client binary. It
should match the OCP cluster's minor release.
|===

To see all the available template parameters, execute the following commands:

1. Switch to sdi-observer project:
+
....
# oc project sdi-observer
# # or alternatively, create it if it does not exist yet
# oc new-project sdi-observer
....
+
2. Make the template available on the cluster, please replace the `ocp-template.json` suffix with
   the xref:template-flavours[template file name] of your choice:
+
....
# oc create -f https://raw.githubusercontent.com/redhat-sap/sap-data-intelligence/master/observer/ocp-template.json
....
+
3. Describe the template:
+
....
# oc describe template
....

==== Disconnected OCP cluster

The prerequisite is a local registry deployed external to the OCP cluster, secured by TLS and
suitable to host the SAP Date Intelligence container images.

[[disconnected-mgmt-on]]
===== Where the management host _has_ access to internet

In this case only the OCP cluster does not have access to the internet. On the other hand,
management host has access to the local container image registry as well as OCP
cluster.

1. Mirror the SDI Observer image to the local registry. For example, on RHEL8:
+
....
# podman login local.image.registry:5000    # if the local registry requires authentication
# skopeo copy \
    docker://quay.io/redhat-sap-cop/sdi-observer:latest-ocp4.6 \
    docker://local.image.registry:5000/sdi-observer:latest-ocp4.6
....
+
.Please make sure to modify the `4.6` suffix according to your OCP server minor release.
+
2. Execute the same steps as outlined in xref:tmpl-run[Template instantiation] while making sure that in step 2,
   `FLAVOUR` is set to the `ocp-prebuilt` and `IMAGE_PULL_SPEC` to your `local.image.registry:5000`

===== Where the management host _lacks_ access to internet

Same as xref:disconnected-mgmt-on[] with the management host having no access to the internet.

1. On a host with access to the internet, copy the SDI Observer image to an archive on USB drive.
For example, on RHEL8:
+
....
# skopeo copy \
    docker://quay.io/redhat-sap-cop/sdi-observer:latest-ocp4.6 \
    oci-archive:/var/run/user/1000/usb-disk/sdi-observer.tar:latest-ocp4.6
....
+
2. Still on the host, clone the Observer git repository to the drive:
+
....
# cd /var/run/user/1000/usb-disk/
# git clone https://github.com/redhat-sap/sap-data-intelligence
....
+
3. Plug the USB drive to the management host (with no access to internet) and mirror the image
   from it to your `local.image.registry:5000`:
+
....
# skopeo copy \
    oci-archive:/var/run/user/1000/usb-disk/sdi-observer.tar:latest-ocp4.6 \
    docker://local.image.registry:5000/sdi-observer:latest-ocp4.6
....
+
4. Copy the git repository from the drive to a local directory.
+
** If there is already a local directory existing, stash the local changes, merge the remote
   changes and apply the stashed changes again on the latest code:
+
....
# cd ~/sap-data-intelligence
# git stash         # temporarily remove local changes
# git remote add drive /var/run/user/1000/usb-disk/sap-data-intelligence
# git fetch drive
# git merge drive   # apply the latest changes from drive to the local checkout
# git stash pop     # re-apply the local changes on top of the latest code
....
+
** Otherwise, clone the git repository to a local directory:
+
....
# git clone /var/run/user/1000/usb-disk/sap-data-intelligence ~/sap-data-intelligence
....
+
5. Edit the `observer/run-observer-template.sh` file in your favorite editor. Especially, mind the
   `FLAVOUR`, `NAMESPACE`, `SDI_NAMESPACE`, `IMAGE_PULL_SPEC` and `SDI_OBSERVER_REPOSITORY`
   parameters. Based on this example, at least the following shall be set:
+
....
FLAVOUR=ubi-prebuilt
IMAGE_PULL_SPEC=local.image.registry:5000/sdi-observer:latest-ocp%%OCP_MINOR_RELEASE%%
SDI_OBSERVER_REPOSITORY="$HOME/sap-data-intelligence"
....
+
** local changes to `observer/run-observer-template.sh` can always be inspected with `git diff`
+
6. Run it in bash like this:
+
....
# bash ./observer/run-observer-template.sh
....
+
7. Keep the local git repository checkout locally for future updates.

== Update instructions

So far, updates need to be performed manually.

1. Backup the previous `run-observer-template.sh` script and open it as long as available. If not
   available, run the following to see the previous environment variables:
+
....
# oc set env --list dc/sdi-observer -n "${NAMESPACE:-sdi-observer}"
....
+
2. Download the run script from git repository like this:
+
....
# curl -O https://raw.githubusercontent.com/redhat-sap/sap-data-intelligence/master/observer/run-observer-template.sh
....
+
3. Edit the downloaded `run-observer-template.sh` file in your favorite editor. Especially, mind
   the `FLAVOUR`, `NAMESPACE`, `SDI_NAMESPACE` and `OCP_MINOR_RELEASE` parameters. Compare it
   against the old `run-observer-template.sh` or against the output of
   `oc set env --list dc/sdi-observer` and update the parameters accordingly.
+
4. Continue with the xref:#tmpl-run[regular template instantiation] starting with the step 3.

== Deprecated parameters

The following parameters will be removed in future versions of SDI Observer.

[width="100%",cols="22%,12%,21%,45%",options="header",]
|===
|Parameter |Since footnote:[deprecated since SDI Observer release] |Substitutes |Description
|`REGISTRY` |0.1.13 |`SDI_REGISTRY_ROUTE_HOSTNAME`, `MANAGE_VSYSTEM_ROUTE`, `INJECT_CABUNDLE` |The registry to mark
as insecure. If not given, it will be determined from the
installer-config secret in the `SDI_NAMESPACE.` If `DEPLOY_SDI_REGISTRY`
is set to `true`, this variable will be used as the container image
registry’s hostname when creating the corresponding route.

|`MARK_REGISTRY_INSECURE` |0.1.13 |`INJECT_CABUNDLE`,
`CABUNDLE_SECRET_NAME` |Set to true if the given or configured
`REGISTRY` shall be marked as insecure in all instances of Pipeline
Modeler.

|`DEPLOY_LETSENCRYPT` |0.1.13 | |Whether to deploy letsencrypt
controller. Requires project admin role attached to the sdi-observer
service account.

|`LETSENCRYPT_REVISION` |0.1.13 | |Revision of letsencrypt repository to
check out.

|`LETSENCRYPT_REPOSITORY` |0.1.13 | |Unless given, a local copy will be
used.

|`EXPOSE_WITH_LETSENCRYPT` |0.1.13 | |Whether to expose routes annotated
for letsencrypt controller. Requires project admin role attached to the
sdi-observer service account. Letsencrypt controller must be deployed
either via this observer or cluster-wide for this to have an effect.
Defaults to the value of `DEPLOY_LETSENCRYPT`
|===
